{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocr2_Final_1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR7uYlUZkxOO"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.contours import sort_contours\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gE5cMnRbhWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805e1ca3-c116-4fdb-de62-edcf1cfe94e8"
      },
      "source": [
        "# from sklearn.metrics import mean_squared_error\n",
        "!pip install scikit-image\n",
        "from skimage import measure"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbnugdk4k_7D"
      },
      "source": [
        "def load_az_dataset(datasetPath):\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\n",
        "\tfile = open(datasetPath)\n",
        "\tfor row in file:\n",
        "\n",
        "\t\trow = row.split(\",\")\n",
        "\t\tlabel = int(row[0])\n",
        "\t\timage = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
        "\n",
        "\t\timage = image.reshape((28, 28))\n",
        "\t\tdata.append(image)\n",
        "\t\tlabels.append(label)\n",
        "\tdata = np.array(data, dtype=\"float32\")\n",
        "\tlabels = np.array(labels, dtype=\"int\")\n",
        "\treturn (data, labels)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOte1QzplGHG"
      },
      "source": [
        "def load_mnist_dataset():\n",
        "\n",
        "\t((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()\n",
        "\tdata = np.vstack([trainData, testData])\n",
        "\tlabels = np.hstack([trainLabels, testLabels])\n",
        "\treturn (data, labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr-3V9g6lJcQ"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import build_montages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GagOLJhox9u"
      },
      "source": [
        "# Setting up hyperparameters\n",
        "EPOCHS = 10\n",
        "INIT_LR = 1e-1\n",
        "BS = 128"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF5LZJGQp86e",
        "outputId": "90320d6e-25d2-4669-fe08-aacb7ee4ba04"
      },
      "source": [
        "# load the A-Z and MNIST datasets, respectively\n",
        "print(\"[INFO] loading datasets...\")\n",
        "(azData, azLabels) = load_az_dataset('/content/drive/MyDrive/CV/A_Z Handwritten Data/A_Z Handwritten Data.csv')\n",
        "(digitsData, digitsLabels) = load_mnist_dataset()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading datasets...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3FzcTn2iQ4-",
        "outputId": "40b56edc-bc2a-4fb7-97a8-f4fde84f1bf7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3El5A6_YswL3"
      },
      "source": [
        "azLabels += 10\n",
        "data = np.vstack([azData, digitsData])\n",
        "labels = np.hstack([azLabels, digitsLabels])\n",
        "# Resizing the image to 32 x 32\n",
        "data = [cv2.resize(image, (32, 32)) for image in data]\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "# Normalising the data\n",
        "data = np.expand_dims(data, axis=-1)\n",
        "data /= 255.0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oue3VTmPvRVg"
      },
      "source": [
        "le = LabelBinarizer()\n",
        "labels = le.fit_transform(labels)\n",
        "counts = labels.sum(axis=0)\n",
        "classTotals = labels.sum(axis=0)\n",
        "classWeight = {}\n",
        "\n",
        "for i in range(0, len(classTotals)):\n",
        "\tclassWeight[i] = classTotals.max() / classTotals[i]\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tlabels, test_size=0.20, stratify=labels, random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_R-C6TvWek"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "\trotation_range=10,\n",
        "\tzoom_range=0.05,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=False,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZRpRqCd7tAD"
      },
      "source": [
        "# Creating CNN model \n",
        "from keras.models import Sequential\n",
        "#creating model object\n",
        "model=Sequential()\n",
        "\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
        "\n",
        "#adding layers and forming the model\n",
        "model.add(Conv2D(32,kernel_size=5,strides=1,padding=\"Same\",activation=\"relu\",input_shape=(32,32,1)))\n",
        "model.add(MaxPooling2D(padding=\"same\"))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling2D(padding=\"same\"))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(36,activation=\"softmax\"))\n",
        "\n",
        "#compiling\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adamax',metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqa6jSEEwENa",
        "outputId": "9b4b3cc3-ec57-44cc-ec79-17b8da4b9e03"
      },
      "source": [
        "# training the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS,\n",
        "\tclass_weight=classWeight,\n",
        "\tverbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/10\n",
            " 141/2765 [>.............................] - ETA: 1:35 - loss: 11.6084 - accuracy: 0.3303"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgYrK4RnayGq"
      },
      "source": [
        "# define the list of label names\n",
        "labelNames = \"0123456789\"\n",
        "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "labelNames = [l for l in labelNames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYVCUB3Aa1pJ"
      },
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=BS)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=labelNames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf_IT6ZmC9tw"
      },
      "source": [
        "# Low Level Vision\n",
        "image = cv2.imread('/content/drive/MyDrive/CV/abcd.png')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "# perform edge detection, find contours in the edge map, and sort the\n",
        "# resulting contours from left-to-right\n",
        "edged = cv2.Canny(blurred, 30, 150)\n",
        "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
        "# initialize the list of contour bounding boxes and associated\n",
        "# characters that we'll be OCR'ing\n",
        "chars = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRjs7g2wGIqv"
      },
      "source": [
        "for c in cnts:\n",
        "\t(x, y, w, h) = cv2.boundingRect(c)\n",
        "\tif (w >= 5 and w <= 150) and (h >= 15 and h <= 120):\n",
        "\t\troi = gray[y:y + h, x:x + w]\n",
        "\t\tthresh = cv2.threshold(roi, 0, 255,\n",
        "\t\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\tif tW > tH:\n",
        "\t\t\tthresh = imutils.resize(thresh, width=32)\n",
        "\t\telse:\n",
        "\t\t\tthresh = imutils.resize(thresh, height=32)\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
        "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
        "\t\t# pad the image and force 32x32 dimensions\n",
        "\t\tpadded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
        "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
        "\t\t\tvalue=(0, 0, 0))\n",
        "\t\tpadded = cv2.resize(padded, (32, 32))\n",
        "\t\t# prepare the padded image for classification via our\n",
        "\t\t# handwriting OCR model\n",
        "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
        "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
        "\t\t# update our list of characters that will be OCR'd\n",
        "\t\tchars.append((padded, (x, y, w, h)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0MJMKi2Gkqh"
      },
      "source": [
        "# extract the bounding box locations and padded characters\n",
        "boxes = [b[1] for b in chars]\n",
        "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
        "# OCR the characters using our handwriting recognition model\n",
        "preds = model.predict(chars)\n",
        "# define the list of label names\n",
        "labelNames = \"0123456789\"\n",
        "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "labelNames = [l for l in labelNames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7HzQGQBHKdu"
      },
      "source": [
        "save=[]\n",
        "bosx=[]\n",
        "for (pred, (x, y, w, h)) in zip(preds, boxes):\t\n",
        "\t# find the index of the label with the largest corresponding\n",
        "\t# probability, then extract the probability and label\n",
        "\ti = np.argmax(pred)\n",
        "\tprob = pred[i]\n",
        "\tlabel = labelNames[i]\n",
        "\t# draw the prediction on the image\n",
        "\tprint(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
        "\tprint(prob)\n",
        "\tprint(label)\n",
        "\tif(prob>0.99):\n",
        "\t  save.append(label)\n",
        "\t  bosx.append((x,y,w,h))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOvR_dspHN6k"
      },
      "source": [
        "# General information\n",
        "print(len(save))\n",
        "print(len(bosx))\n",
        "print(save)\n",
        "print(bosx[17])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs-j7hMCQk_4"
      },
      "source": [
        "image1 = cv2.imread('/content/Hello4.jpeg')\n",
        "gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "# perform edge detection, find contours in the edge map, and sort the\n",
        "# resulting contours from left-to-right\n",
        "edged = cv2.Canny(blurred, 30, 150)\n",
        "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
        "# initialize the list of contour bounding boxes and associated\n",
        "# characters that we'll be OCR'ing\n",
        "chars = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNa3a1pJTUTH"
      },
      "source": [
        "for c in cnts:\n",
        "\t(x, y, w, h) = cv2.boundingRect(c)\n",
        "\tif (w >= 5 and w <= 150) and (h >= 15 and h <= 120):\n",
        "\t\troi = gray[y:y + h, x:x + w]\n",
        "\t\tthresh = cv2.threshold(roi, 0, 255,\n",
        "\t\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\tif tW > tH:\n",
        "\t\t\tthresh = imutils.resize(thresh, width=32)\n",
        "\t\telse:\n",
        "\t\t\tthresh = imutils.resize(thresh, height=32)\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
        "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
        "\t\t# pad the image and force 32x32 dimensions\n",
        "\t\tpadded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
        "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
        "\t\t\tvalue=(0, 0, 0))\n",
        "\t\tpadded = cv2.resize(padded, (32, 32))\n",
        "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
        "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
        "\t\t# update our list of characters that will be OCR'd\n",
        "\t\tchars.append((padded, (x, y, w, h)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRpdNVT4Ta4p"
      },
      "source": [
        "# extract the bounding box locations and padded characters\n",
        "boxes = [b[1] for b in chars]\n",
        "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
        "# OCR the characters using our handwriting recognition model\n",
        "preds = model.predict(chars)\n",
        "# define the list of label names\n",
        "labelNames = \"0123456789\"\n",
        "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "labelNames = [l for l in labelNames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV9mdXP0vj63"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw6Y1OXgTdW6"
      },
      "source": [
        "c=0\n",
        "count=0\n",
        "p=0\n",
        "for (pred, (x, y, w, h)) in zip(preds, boxes)\t\n",
        "\t# find the index of the label with the largest corresponding\n",
        "\t# probability, then extract the probability and label\n",
        "  i = np.argmax(pred)\n",
        "  prob = pred[i]\n",
        "  label = labelNames[i]\n",
        "\t# draw the prediction on the image\n",
        "  # print(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
        "  x1=0\n",
        "  y1=0\n",
        "  w1=0\n",
        "  h1=0\n",
        "\t# print(label)\n",
        "  for zi in range(0,25):\n",
        "\t  if(save[zi]==label):\n",
        "\t    # print(zi)\n",
        "\t    (x1,y1,w1,h1)=(bosx[zi])\n",
        "\n",
        "\t# cv2.rectangle(image1, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\t# cv2.putText(image1, label, (x - 10, y - 10),\n",
        "\t# \tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
        "  img_res = image1[y:y+h,x:x+w]\n",
        "  img_res = cv2.cvtColor(img_res, cv2.COLOR_BGR2GRAY)\n",
        "  img_res = cv2.resize(img_res,(14,14))\n",
        "  img_res1 = image[y1:y1+h1,x1:x1+w1]\n",
        "\t# print(img_res1)\n",
        "  def mse(imageA, imageB):\n",
        "\t  err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "\t  err /= float(imageA.shape[0] * imageA.shape[1])\n",
        "\t  return err\n",
        "\t  \n",
        "  def compare_images(imageA, imageB):\n",
        "    # compute the mean squared error and structural similarity\n",
        "    # index for the images\n",
        "\t  m = mse(imageA, imageB)\n",
        "   \t# ss = measure.compare_ssim(imageA, imageB)\n",
        "\t  s = measure.compare_ssim(imageA, imageB)\n",
        "\t  return s\n",
        "  if(img_res1.size != 0):\n",
        "\t  \n",
        "\t  img_res1 = cv2.cvtColor(img_res1, cv2.COLOR_BGR2GRAY)\n",
        "\t  img_res1 = cv2.resize(img_res1,(14,14))\n",
        "\t  cv2.rectangle(image1, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\t  cv2.putText(image1, label, (x - 10, y - 10),\n",
        "\t  cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
        "\t  cv2_imshow(image1)\n",
        "\t  ss=compare_images(img_res,img_res1)\n",
        "\t  c=c+ss\n",
        "\t  count=count+1\n",
        "\t  p=c/count\n",
        "\n",
        "# print(\"pPPP\")\n",
        "print(p)\n",
        "for (pred, (x, y, w, h)) in zip(preds, boxes):\t\n",
        "\t# find the index of the label with the largest corresponding\n",
        "\t# probability, then extract the probability and label\n",
        "  i = np.argmax(pred)\n",
        "  prob = pred[i]\n",
        "  label = labelNames[i]\n",
        "\t# draw the prediction on the image\n",
        "  print(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
        "  x1=0\n",
        "  y1=0\n",
        "  w1=0\n",
        "  h1=0\n",
        "\t# print(label)\n",
        "  for zi in range(0,25):\n",
        "\t  if(save[zi]==label):\n",
        "\t    print(zi)\n",
        "\t    (x1,y1,w1,h1)=(bosx[zi])\n",
        "  img_res = image1[y:y+h,x:x+w]\n",
        "  img_res = cv2.cvtColor(img_res, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  img_res = cv2.resize(img_res,(14,14))\n",
        "  img_res1 = image[y1:y1+h1,x1:x1+w1]\n",
        "\t# print(img_res1)\n",
        "  def mse(imageA, imageB):\n",
        "    # the 'Mean Squared Error' between the two images is the\n",
        "    # sum of the squared difference between the two images;\n",
        "    # NOTE: the two images must have the same dimension\n",
        "\t  err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "\t  err /= float(imageA.shape[0] * imageA.shape[1])\n",
        "\n",
        "    # return the MSE, the lower the error, the more \"similar\"\n",
        "    # the two images are\n",
        "\t  return err\n",
        "\t  \n",
        "  def compare_images(imageA, imageB):\n",
        "\t  m = mse(imageA, imageB)\n",
        "\t  s = measure.compare_ssim(imageA, imageB)\n",
        "\t  print(s)\n",
        "\t  return s\n",
        "\n",
        "  if(img_res1.size != 0):\n",
        "\t  \n",
        "\t  img_res1 = cv2.cvtColor(img_res1, cv2.COLOR_BGR2GRAY)\n",
        "\t  img_res1 = cv2.resize(img_res1,(14,14))\n",
        "\t  \n",
        "\t  # ss=compare_images(img_res,img_res1)\n",
        "\t  cv2_imshow(img_res)\n",
        "\t  cv2_imshow(img_res1)\n",
        "\t  ss=compare_images(img_res,img_res1)\n",
        "\t  if(ss>p):\n",
        "\t    print(\"Good\")\n",
        "\t  else:\n",
        "\t    print(\"Bad\")\n",
        "\n",
        "\n",
        "    \n",
        "\t  \n",
        "\n",
        "\t  \n",
        "\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpHU6mYBTjX0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufQ_4o3Idfin"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}